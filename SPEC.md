# プロジェクト仕様書: YouTubeレシピNotion自動登録ツール

## 1. プロジェクト概要

### 1.1. 目的
YouTubeで見つけた料理動画のレシピ情報（材料、手順など）を、簡単な操作でNotionの指定データベースに自動的に登録・整理するためのツールを提供する。

### 1.2. 主要機能
1.  **URL入力UI:** ユーザーがYouTubeの料理動画URLを入力できるWebインターフェース。
2.  **YouTube動画文字起こし:** 入力されたURLの動画から音声を抽出し、`faster-whisper`を使用して高精度な文字起こしを行う。
3.  **レシピ情報抽出:** 文字起こしされたテキストから、AIモデル（LLM）を利用してレシピに関連する情報（材料リスト、調理手順など）を構造化データとして抽出する。
4.  **Notion DB連携:** 抽出されたレシピ情報を、ユーザーが指定したNotionデータベースに新しい行（ページ）として追加する。
5.  **Agent-to-Agent (A2A) アーキテクチャ:** 各主要機能（文字起こし、レシピ抽出、Notion連携）を独立したAIエージェントとして実装し、A2Aプロトコルを通じて連携させる。

### 1.3. ターゲットユーザー
*   料理が好きで、オンライン動画からレシピを収集するユーザー。
*   収集したレシピをNotionで効率的に管理したいユーザー。
*   手動での転記作業を自動化したいユーザー。

### 1.4. 技術スタック (現状および予定)
*   **バックエンド:** Python 3.12
*   **Webフレームワーク:** Flask
*   **WSGIサーバー:** Waitress（本番環境用）
*   **コンテナ化:** Docker, Docker Compose
*   **依存関係管理:** Poetry（すべてのコンポーネントで統一）
*   **文字起こし:** faster-whisper (baseモデル, CPU, int8)
*   **音声ダウンロード:** yt-dlp
*   **レシピ抽出:** 大規模言語モデル (LLM) API (**Gemini API**, OpenAI APIなど)
*   **Notion連携:** Notion API, `notion-client` (Pythonライブラリ)
*   **エージェント間通信:** Agent-to-Agent (A2A) Protocol
*   **環境変数管理:** python-dotenv
*   **ロギング:** 標準ライブラリ logging
*   **フロントエンド:** HTML, CSS, JavaScript + Flaskテンプレート

## 2. UX/UIデザイン

### 2.1. 画面構成
シンプルで単一ページのWebアプリケーションを想定。

*   **ヘッダー:** アプリケーションタイトル
*   **入力セクション:**
    *   ラベル: "YouTube動画のURLを入力してください"
    *   入力フィールド: テキスト入力 (URLペースト用)
    *   実行ボタン: 「レシピをNotionに登録」
*   **ステータス表示セクション:**
    *   処理の進捗状況をリアルタイム（またはステップごと）に表示。
    *   例: 「URLを検証中...」「音声をダウンロード中...」「文字起こし中...」「レシピを抽出中...」「Notionに登録中...」「完了しました！」「エラーが発生しました。」
*   **結果表示セクション (任意):**
    *   成功時: 「Notionに登録しました。」というメッセージと共に、作成されたNotionページへのリンクを表示。
    *   失敗時: エラー内容を分かりやすく表示。
*   **アニメーション・キャラクター:**
    *   進捗表示時にハンバーガーキャラクターがスケートボードで左から右へ移動するアニメーションを表示。
    *   ハンバーガーの顔パーツ（目・眉・頬）はアニメ風に調整され、表情がより可愛く・親しみやすくなっている。
    *   口は表示せず、シンプルな表情。
    *   両側面に手（腕＋手）が付き、ハンバーガー本体の側面に自然に接するように配置。
    *   手・腕のCSSは`bottom`基準で位置指定し、全体のバランスを最適化。
    *   スケートアニメーションは「左→右のみ」の一方向ループ。

### 2.2. ユーザーストーリー
1.  ユーザーはブラウザでツールのWebサイトにアクセスする。
2.  ユーザーは目的のYouTube料理動画のURLをコピーし、入力フィールドにペーストする。
3.  ユーザーは「レシピをNotionに登録」ボタンをクリックする。
4.  システムはバックグラウンドで処理を開始し、ステータス表示セクションに進捗状況を表示する。
5.  システムは順番に文字起こし、レシピ抽出、Notion登録を行う。
6.  全ての処理が正常に完了すると、ステータス表示セクションに完了メッセージが表示され、結果表示セクションに作成されたNotionページへのリンクが表示される。
7.  途中でエラーが発生した場合、ステータス表示セクションにエラーが発生したステップが表示され、結果表示セクションにエラーの詳細が表示される。

### 2.3. デザイン原則
*   **シンプル:** ユーザーが必要な操作はURLの入力とボタンクリックのみ。
*   **明確なフィードバック:** 処理が進行中であること、どのステップを実行中か、結果（成功/失敗）をユーザーに明確に伝える。
*   **効率性:** 手動でのコピー＆ペーストや情報整理の手間を大幅に削減する。
*   **親しみやすさ:** 進捗アニメーションのハンバーガーキャラクターは、アニメ風の顔・両手・スケートボードで親しみやすく、楽しいUI体験を提供する。

## 3. 機能仕様

### 3.1. YouTube動画処理エージェント
*   **目的:** YouTube URLを受け取り、動画から字幕を取得または音声を文字起こしする。また、チャンネル名やサムネイルURLなどのビデオメタデータも取得する。
*   **入力 (A2A Task):** `message.parts` に `youtube_url` を含む `DataPart` または `TextPart`。
*   **処理フロー:**
    1.  URL抽出・検証。
    2.  `yt-dlp`を使用してビデオメタデータ（チャンネル名、サムネイルURL）を取得。
    3.  字幕取得フロー（`USE_SUBTITLES`が有効の場合）:
        a. yt-dlpを使用して手動追加された字幕または自動生成字幕を取得。
        b. 優先言語順（デフォルト: ["ja", "en"]）で字幕を検索。
        c. 字幕ファイル（SRTまたはVTT）からテキスト部分のみを抽出。
    4.  音声文字起こしフロー（字幕が取得できない場合、または`USE_TRANSCRIPTION`が有効の場合）:
        a. `yt-dlp` で音声ダウンロード (MP3形式推奨、一時ファイルとして保存)。
        b. `faster-whisper` (baseモデル, CPU, int8) で文字起こし実行。
        c. 文字起こし結果テキスト生成。
    5.  字幕と文字起こしの両方が有効で利用可能な場合、「【字幕】」と「【文字起こし】」のセクションに分けて結果を提供。
    6.  一時ファイル削除。
    7.  メタデータ（チャンネル名、サムネイルURL）と文字起こし結果を併せて他のエージェントに転送。
*   **出力 (A2A Task):**
    *   成功時: `status: "completed"`, `artifacts`: 
        - 字幕または文字起こし、または両方のテキスト (`text/plain`)
        - ビデオメタデータ(`application/json`) - チャンネル名、サムネイルURL、YouTube URL
        - YouTube URLを`text/uri-list`形式でも送信（複数形式での冗長送信）
    *   失敗時: `status: "failed"`, `error`: エラーコードとメッセージ。
*   **設定オプション:**
    *   `USE_SUBTITLES`: YouTube字幕取得機能の有効/無効（デフォルト: True）
    *   `USE_TRANSCRIPTION`: 音声文字起こし機能の有効/無効（デフォルト: True）
    *   `SUBTITLE_LANG`: 取得する字幕の優先言語リスト（デフォルト: ["ja", "en"]）
*   **エンドポイント:** `/.well-known/agent.json`, `/tasks/send`, `/tasks/get`, `/health`。
*   **A2Aエージェント機能:**
    *   `discover_agents()`: スキル、能力、コンテンツタイプに基づいて他のエージェントを発見
    *   `query_agent_skill()`: 特定のエージェントが特定のスキルを持っているか確認
    *   `query_agent_capability()`: 特定のエージェントが特定の能力を持っているか確認
    *   `can_handle_content()`: 特定のエージェントが特定のコンテンツタイプを処理できるか確認
    *   `analyze_content_type()`: テキストからコンテンツタイプを分析
    *   `send_to_next_agent()`: 次のエージェントにタスクデータを送信
    *   `download_subtitles()`: YouTube動画から字幕を取得
    *   `transcribe_audio()`: 音声を文字起こし
*   **現状:** Flaskで実装済み。Dockerで実行。字幕取得機能と音声文字起こし機能を統合。ビデオメタデータの取得と連携を強化。Docker環境でのホスト名解決問題を修正。エージェント間のデータ転送形式を強化。A2Aプロトコルへの対応強化として`/tasks/get`エンドポイントを追加。ログ機能を強化して動画情報取得時の詳細なトレース情報とエラー処理を実装。
*   **今後の課題:** 非同期処理導入、エラーハンドリングのさらなる強化、モデルロード最適化。
*   **パッケージ更新:** 
    * `hf_xet`パッケージを追加して、Hugging Faceモデルのダウンロード最適化を実施。

### 3.2. レシピ抽出エージェント
*   **目的:** 文字起こしテキストとYouTube URL、およびビデオメタデータ（チャンネル名、サムネイルURL）から、レシピ情報（カテゴリ、難易度、材料、手順）を抽出・整形し、JSONデータとして提供する。
*   **入力 (A2A Task):** `message.parts` 配列内に以下を含む:
    *   文字起こしテキスト (例: `mimeType: "text/plain"`, `text: "..."`)
    *   YouTube URL、チャンネル名、サムネイルURL (例: `data: {"youtube_url": "...", "channel_name": "...", "thumbnail_url": "..."}`)
*   **処理フロー:**
    1.  入力 `parts` から文字起こしテキスト、YouTube URL、チャンネル名、サムネイルURLを取得。
    2.  定義済みプロンプト（URL、チャンネル名、サムネイルURL、カテゴリ、難易度、材料、手順の抽出指示を含む）と共に **Gemini API (JSONモード)** にリクエスト送信。
    3.  LLM応答からレシピ情報を抽出。
    4.  YouTubeエージェントから受け取ったメタデータが欠落している場合は自動補完。
    5.  結果をJSON形式に整形。
*   **出力 (A2A Task):**
    *   成功時: `status: "completed"`, `artifacts`: レシピ情報JSON (`application/json`)。JSONには `recipe_name`, `youtube_url`, `channel_name`, `thumbnail_url`, `category`, `difficulty`, `ingredients`, `instructions` が含まれる。
    *   失敗時: `status: "failed"`, `error`: エラー情報。
*   **A2Aエージェント機能:**
    *   `discover_agents()`: スキル、能力、コンテンツタイプに基づいて他のエージェントを発見
    *   `query_agent_skill()`: 特定のエージェントが特定のスキルを持っているか確認
    *   `query_agent_capability()`: 特定のエージェントが特定の能力を持っているか確認
    *   `can_handle_content()`: 特定のエージェントが特定のコンテンツタイプを処理できるか確認
    *   `analyze_content_type()`: JSONからコンテンツタイプを分析
    *   `send_to_next_agent()`: 次のエージェントにタスクデータを送信
    *   `extract_recipe_from_text()`: 文字起こしテキストからレシピ情報を抽出
*   **現状:** A2Aサーバー、レシピ抽出機能、メタデータ処理機能を実装完了。エージェント間通信でメタデータが確実に転送されるよう改善。JSON検証・補完機能を強化。A2Aプロトコルへの準拠を強化し、メタデータ処理とアーティファクトタイプの設定を改善。タスクの完了処理とレスポンス構造の一貫性を確保。
*   **今後の課題:** プロンプトのさらなるチューニングによる抽出精度向上、エラーハンドリングの強化。

### 3.3. Notion連携エージェント
*   **目的:** 抽出されたレシピ情報を指定Notion DBに追加。
*   **入力 (A2A Task):** `message.parts` にレシピ情報JSON (`application/json`)。
*   **処理フロー:**
    1.  入力JSON取得。
    2.  Notion API認証。
    3.  入力データをNotion DBのプロパティにマッピング。
    4.  サムネイル画像とYouTubeリンクをページ本文に追加。
    5.  Notion API (`pages.create`) でページ追加。
    6.  作成されたページのURLをMetadataとして次のエージェントに転送。
*   **出力 (A2A Task):**
    *   成功時: `status: "completed"`, `artifacts`: 作成されたNotionページURL (`text/uri-list` or `application/json`)、メタデータには`notion_url`を含む。
    *   失敗時: `status: "failed"`, `error`: エラー情報。
*   **A2Aエージェント機能:**
    *   `discover_agents()`: スキル、能力、コンテンツタイプに基づいて他のエージェントを発見
    *   `query_agent_skill()`: 特定のエージェントが特定のスキルを持っているか確認
    *   `query_agent_capability()`: 特定のエージェントが特定の能力を持っているか確認
    *   `can_handle_content()`: 特定のエージェントが特定のコンテンツタイプを処理できるか確認
    *   `validate_and_preprocess_recipe_data()`: レシピデータのバリデーションと前処理
*   **現状:** A2AサーバーとNotion連携機能を実装完了。メタデータ（サムネイルURLとチャンネル名）の処理を強化。サムネイルURLをNotionページ本文に画像として表示する機能を追加。エラーハンドリングを強化。A2Aプロトコルに準拠したメタデータとアーティファクト処理を実装し、フロー完了を明示するためのメタデータを追加。
*   **今後の課題:** UXのさらなる改善、Notion DBスキーマの柔軟な対応。

### 3.4. フロントエンドUI / メインコントローラー
*   **目的:** ユーザーインターフェースを提供し、各A2Aエージェントの処理を連携・制御する。
*   **機能:**
    1.  URL入力受付、実行トリガー。
    2.  A2Aクライアントとして各エージェントに順次 `/tasks/send` リクエストを送信。
    3.  各エージェントのタスク完了（または失敗）を待機（ポーリング or より高度な方法）。
    4.  エージェント間でデータを引き渡し。
    5.  処理全体の進捗状況と最終結果をUIに表示。
*   **現状:** 
    *   基本的なUI（URL入力、ボタン、ステータス表示）を実装完了。
    *   YouTubeエージェント連携と進捗ポーリング機能を実装。
    *   タスク完了検出方法を改良（複数の検出方法を組み合わせて堅牢性を向上）。
    *   A2Aプロトコルの`/tasks/get`エンドポイントを活用した完了検出を実装。
    *   エラー処理を強化し、タイムアウト処理を最適化（完了推定のための時間閾値を短縮）。
    *   完了時にNotionページURLを表示する機能を追加。
*   **今後の課題:** 
    *   処理状態の視覚的フィードバックのさらなる改善。
    *   エラーハンドリングのさらなる強化。

## 4. A2A連携アーキテクチャ

*   各主要機能（YouTube処理、レシピ抽出、Notion連携）は、それぞれ独立したA2Aサーバー（エージェント）として動作する。
*   フロントエンドUI/メインコントローラーがA2Aクライアントの役割を担い、これらのエージェントと通信して一連のワークフローを実行する。
*   エージェント間のデータ受け渡しは、A2A Taskの `artifacts` フィールドを通じて行われる。
*   メタデータフィールドを利用して、処理の進行状況や追加情報（NotionページURLなど）を伝達。
*   データ形式の標準化と複数形式での送信により、エージェント間の互換性と情報伝達の確実性を確保。
*   タスクの実行（特に時間のかかる文字起こしやLLM処理）は非同期で行い、クライアント側でタスク状態をポーリングして完了を待機。
*   A2Aプロトコルの`/tasks/get`エンドポイントを実装して、タスク状態の効率的な取得と完了通知を実現。

## 5. プロジェクト構造

### 5.1. ディレクトリ構造
プロジェクトは以下のディレクトリ構造で整理されています：

```
recipe-scraper/
│
├── agents/                           # 各エージェントのディレクトリ
│   ├── youtube_agent/               # YouTube処理エージェント
│   │   ├── main.py                  # YouTubeエージェントのメインコード
│   │   ├── Dockerfile               # YouTubeエージェントのDockerfile
│   │   ├── pyproject.toml           # 依存関係定義ファイル
│   │   ├── poetry.lock              # 依存関係のロックファイル
│   │   └── agent_card.json          # エージェント定義ファイル
│   │
│   ├── recipe_agent/                # レシピ抽出エージェント
│   │   ├── main.py                  # レシピエージェントのメインコード
│   │   ├── recipe_extractor.py      # レシピ抽出ロジック
│   │   ├── Dockerfile               # レシピエージェントのDockerfile
│   │   ├── pyproject.toml           # 依存関係定義ファイル
│   │   ├── poetry.lock              # 依存関係のロックファイル
│   │   └── agent_card.json          # エージェント定義ファイル
│   │
│   └── notion_agent/                # Notion連携エージェント
│       ├── main.py                  # Notionエージェントのメインコード
│       ├── notion_handler.py        # Notion API連携ロジック
│       ├── Dockerfile               # NotionエージェントのフロントエンドのDockerfile
│       ├── pyproject.toml           # 依存関係定義ファイル
│       ├── poetry.lock              # 依存関係のロックファイル
│       └── agent_card.json          # エージェント定義ファイル
│
├── frontend/                         # フロントエンドUI
│   ├── main.py                      # フロントエンドのメインコード
│   ├── templates/                   # HTMLテンプレート
│   │   └── index.html               # メインページ
│   ├── static/                      # 静的ファイル
│   │   ├── css/                     # CSSファイル
│   │   │   └── style.css            # メインスタイルシート
│   │   └── js/                      # JavaScriptファイル
│   │       └── main.js              # メインJSファイル
│   ├── Dockerfile                   # フロントエンドのDockerfile
│   ├── pyproject.toml               # 依存関係定義ファイル
│   ├── poetry.lock                  # 依存関係のロックファイル
│   └── README.md                    # フロントエンド説明書
│
├── tests/                           # テストコード
│├── integration_test.py              # 統合テスト用スクリプト
│
├── docker-compose.yml               # Dockerコンポーズ設定ファイル
├── .env                             # 環境変数設定ファイル
├── .env.example                     # 環境変数設定ファイルの例
├── .gitignore                       # Gitの無視設定ファイル
└── README.md                        # プロジェクト説明書
```

### 5.2. Docker構成
本プロジェクトは完全にコンテナ化され、各エージェントは独立したコンテナとして実行されます：

*   **youtube-agent**: YouTube動画の処理を担当
*   **recipe-extractor**: レシピ情報の抽出を担当
*   **notion-agent**: Notion DBへの登録を担当
*   **frontend**: ユーザーインターフェースとエージェント連携を担当

### 5.3. 依存関係管理
本プロジェクトでは、環境の再現性と一貫性を確保するために以下の方針を採用しています：

*   すべてのエージェントで **Poetry** を使用して依存関係を管理
*   各エージェントディレクトリに `pyproject.toml` と `poetry.lock` ファイルを配置
*   `poetry.lock` ファイルをリポジトリに含めることで、全環境で一貫した依存関係バージョンを保証
*   Dockerビルド時に既存の `poetry.lock` ファイルを使用し、環境間の一貫性を確保
*   特定の依存パッケージの更新が必要な場合は、`poetry update` コマンドで更新し、生成された新しい `poetry.lock` ファイルをコミット

### 5.4. Docker最適化
各エージェントのDockerfileを最適化し、より再現性の高いビルドを実現しています：

*   `RUN poetry lock` コマンドを削除し、既存の `poetry.lock` ファイルを使用するように変更
*   `COPY pyproject.toml poetry.lock /app/` で両ファイルを同時にコピーし、キャッシュ効率を向上
*   ルートディレクトリの冗長な `Dockerfile` を削除し、各エージェント個別の Dockerfile のみを使用
*   YouTube動画処理エージェントに `hf_xet` パッケージを追加し、Hugging Faceモデルのダウンロードを最適化

## 6. インストールと実行方法

### 6.1. 必要条件
*   Docker
*   Docker Compose
*   API キー
    *   Gemini API キー (Google AI Studio から取得)
    *   Notion API キーと Database ID

### 6.2. インストール手順
1.  リポジトリをクローン:
    ```bash
    git clone <repository-url>
    cd recipe-scraper
    ```

2.  環境変数を設定 (.env ファイル):
    ```bash
    cp .env.example .env
    # エディタで .env を開いて API キーなどを設定
    ```

3.  Docker Compose でビルド:
    ```bash
    docker-compose build
    ```

### 6.3. 実行方法
```bash
docker-compose up
```
その後、ブラウザで `http://localhost:5003` にアクセス。

## 7. テスト
### 7.1. 統合テスト
統合テストは `integration_test.py` ファイルに実装されています。このテストスイートでは、YouTubeエージェントからNotionエージェントまでの一連の処理フローが正しく機能することを検証します。テストを実行するには以下のコマンドを使用してください：

## 8. セキュリティ考慮事項

*   API キーは環境変数として設定し、コードに直接記述しない。
*   ユーザー入力 (URLs) は適切に検証・サニタイズする。

## 9. 将来的な拡張

*   **マルチユーザー対応:** 認証機能を追加し、ユーザーごとに異なるNotion DBを指定できるようにする。
*   **レシピカテゴリのカスタマイズ:** ユーザーが自分でレシピカテゴリを定義・管理できるようにする。
*   **バッチ処理:** 複数のYouTube URLを一度に処理できるようにする。
*   **進捗状況のより詳細な表示:** 各処理ステップの進捗率を視覚的に表示する。
*   **FastAPIへの移行:** async/awaitに非同期処理・処理キャンセル機能の実装する。
*   **型アノテーションの活用:** Pydanticによる入出力の検証ができるようにする。
